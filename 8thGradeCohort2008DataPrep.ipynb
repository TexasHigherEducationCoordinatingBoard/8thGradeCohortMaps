{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This program prepares the selected data from 2008, Texas 8th Grade Cohort Longitudinal Study for mapping\n",
    "\n",
    "### Begin by downloading the Cohort Workbook from [the THECB website](http://www.txhighereddata.org/index.cfm?objectId=F2CBE4A0-C90B-11E5-8D610050560100A9). \n",
    "\n",
    "The selected data focus on enrollment and completion rates in higher education. In addittion to examining the overall cohort, the data also describe the target populations from the Texas Higher Education Strategic Plan - African American, Hispanic, economically disadvantaged, and male students. These are groups that have had historically lower rates of participation and success in higher education. Data is reported by TEA Region.\n",
    "\n",
    "Save the workbook in 'Data\\8th Grade FY2008 Cohort Workbook.xlsx'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import zipfile\n",
    "import arcpy\n",
    "import io\n",
    "import os\n",
    "\n",
    "arcpy.env.overwriteOutput = True\n",
    "pd.options.display.max_rows = 10\n",
    "\n",
    "#Make Geodatabase if it doesn't exist\n",
    "if not os.path.exists(\"Data/Cohort.gbd\"):\n",
    "    arcpy.CreateFileGDB_management(\"Data\",\"Cohort.gdb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the gender by ethnicity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    TEAReg      RegName  Gender               Eth    CohoN    nEnr    pEnr  \\\n",
      "0        1     Edinburg  Female  African American     29.0    19.0  0.6552   \n",
      "1        1     Edinburg  Female          Hispanic  12703.0  7537.0  0.5933   \n",
      "2        1     Edinburg  Female             White    319.0   213.0  0.6677   \n",
      "3        1     Edinburg  Female            Others     69.0    37.0  0.5362   \n",
      "4        1     Edinburg    Male  African American     36.0    23.0  0.6389   \n",
      "..     ...          ...     ...               ...      ...     ...     ...   \n",
      "155     20  San Antonio  Female            Others    280.0   188.0  0.6714   \n",
      "156     20  San Antonio    Male  African American   1102.0   528.0  0.4791   \n",
      "157     20  San Antonio    Male          Hispanic   9226.0  3979.0  0.4313   \n",
      "158     20  San Antonio    Male             White   3538.0  1994.0  0.5636   \n",
      "159     20  San Antonio    Male            Others    264.0   172.0  0.6515   \n",
      "\n",
      "      nComp   pComp  \n",
      "0      11.0  0.3793  \n",
      "1    3341.0  0.2630  \n",
      "2     121.0  0.3793  \n",
      "3      25.0  0.3623  \n",
      "4       9.0  0.2500  \n",
      "..      ...     ...  \n",
      "155   123.0  0.4393  \n",
      "156   130.0  0.1180  \n",
      "157  1301.0  0.1410  \n",
      "158  1055.0  0.2982  \n",
      "159    93.0  0.3523  \n",
      "\n",
      "[160 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "xl = pd.read_excel('Data\\8th Grade FY2008 Cohort Workbook.xlsx', sheet_name='TEA by Gender by Ethnicity', header=None, index_col=None, skiprows=6)\n",
    "\n",
    "#Keep the columns you need\n",
    "xl2=xl[[0,1,2,3,4,17,18,21,22]]\n",
    "\n",
    "#Drop the rows you don't need and then name the columns\n",
    "GenEth=xl2[:160]\n",
    "GenEth.columns=['TEAReg','RegName','Gender','Eth', 'CohoN', 'nEnr', 'pEnr', 'nComp', 'pComp']\n",
    "\n",
    "print(GenEth)  #Check results to be sure you grabbed all the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collapse on ethicity to remove gender to get African American and Hispanic totals by region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    TEAReg         RegName   AACoho  AAnEnr  AAnComp     AApEnr    AApComp\n",
      "0        1        Edinburg     65.0    42.0     20.0  64.615385  30.769231\n",
      "1        2  Corpus Christi    291.0   146.0     37.0  50.171821  12.714777\n",
      "2        3        Victoria    396.0   210.0     45.0  53.030303  11.363636\n",
      "3        4         Houston  16341.0  9148.0   2491.0  55.981886  15.243865\n",
      "4        5        Beaumont   1777.0   951.0    250.0  53.517164  14.068655\n",
      "..     ...             ...      ...     ...      ...        ...        ...\n",
      "15      16        Amarillo    323.0   173.0     35.0  53.560372  10.835913\n",
      "16      17         Lubbock    433.0   201.0     47.0  46.420323  10.854503\n",
      "17      18         Midland    244.0   108.0     35.0  44.262295  14.344262\n",
      "18      19         El Paso    384.0   166.0     48.0  43.229167  12.500000\n",
      "19      20     San Antonio   2110.0  1089.0    371.0  51.611374  17.582938\n",
      "\n",
      "[20 rows x 7 columns]\n",
      "    TEAReg         RegName  HisCoho  HisnEnr  HisnComp    HispEnr   HispComp\n",
      "0        1        Edinburg  25765.0  14238.0    5617.0  55.261013  21.800893\n",
      "1        2  Corpus Christi   5124.0   2501.0     840.0  48.809524  16.393443\n",
      "2        3        Victoria   1810.0    748.0     240.0  41.325967  13.259669\n",
      "3        4         Houston  30602.0  13570.0    4935.0  44.343507  16.126397\n",
      "4        5        Beaumont    660.0    265.0     136.0  40.151515  20.606061\n",
      "..     ...             ...      ...      ...       ...        ...        ...\n",
      "15      16        Amarillo   2177.0    964.0     334.0  44.281121  15.342214\n",
      "16      17         Lubbock   2691.0   1132.0     355.0  42.066146  13.192122\n",
      "17      18         Midland   3142.0   1389.0     466.0  44.207511  14.831318\n",
      "18      19         El Paso  11246.0   6737.0    2193.0  59.905744  19.500267\n",
      "19      20     San Antonio  17903.0   8731.0    3266.0  48.768363  18.242753\n",
      "\n",
      "[20 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "#Keep Hispanic and African American counts, collapse to remove gender, and then calculate percents \n",
    "EthCounts=GenEth.drop(GenEth.columns[[2,6,8]], axis=1) #axis=0 for rows, axis=1 for columns\n",
    "\n",
    "#Make African American Group\n",
    "AAtemp=EthCounts.loc[EthCounts['Eth']=='African American'].copy() #copy to avoid chained indexing\n",
    "AA=AAtemp.groupby([\"TEAReg\", \"RegName\",\"Eth\"], as_index=False).sum()\n",
    "AA['AApEnr']=100*AA['nEnr']/AA['CohoN']\n",
    "AA['AApComp']=100*AA['nComp']/AA['CohoN']\n",
    "AA=AA.drop(['Eth'], axis=1) \n",
    "AA.columns=['TEAReg','RegName','AACoho', 'AAnEnr','AAnComp','AApEnr','AApComp']\n",
    "\n",
    "#Make Hispanic Group\n",
    "Hisptemp=EthCounts.loc[EthCounts['Eth']=='Hispanic'].copy() #copy to avoid chained indexing\n",
    "Hisp=Hisptemp.groupby([\"TEAReg\", \"RegName\",\"Eth\"], as_index=False).sum()\n",
    "Hisp['HispEnr']=100*Hisp['nEnr']/Hisp['CohoN']\n",
    "Hisp['HispComp']=100*Hisp['nComp']/Hisp['CohoN']\n",
    "Hisp=Hisp.drop(['Eth'], axis=1)\n",
    "Hisp.columns=['TEAReg','RegName','HisCoho', 'HisnEnr','HisnComp','HispEnr','HispComp']\n",
    "\n",
    "print(AA) #Check results\n",
    "print(Hisp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data on male students by TEA region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    TEAReg         RegName  TotmCoho  TotmnEnr  TotmnComp   TotmpEnr  \\\n",
      "0        1        Edinburg   13548.0    7016.0     2428.0  51.786242   \n",
      "1        2  Corpus Christi    3921.0    1842.0      648.0  46.977812   \n",
      "2        3        Victoria    2013.0     953.0      419.0  47.342275   \n",
      "3        4         Houston   37913.0   18928.0     7201.0  49.924828   \n",
      "4        5        Beaumont    3006.0    1411.0      539.0  46.939454   \n",
      "..     ...             ...       ...       ...        ...        ...   \n",
      "15      16        Amarillo    2987.0    1459.0      561.0  48.844995   \n",
      "16      17         Lubbock    2771.0    1290.0      514.0  46.553591   \n",
      "17      18         Midland    2733.0    1125.0      385.0  41.163557   \n",
      "18      19         El Paso    6484.0    3574.0     1032.0  55.120296   \n",
      "19      20     San Antonio   14130.0    6673.0     2579.0  47.225761   \n",
      "\n",
      "    TotmpComp  \n",
      "0   17.921464  \n",
      "1   16.526396  \n",
      "2   20.814704  \n",
      "3   18.993485  \n",
      "4   17.930805  \n",
      "..        ...  \n",
      "15  18.781386  \n",
      "16  18.549260  \n",
      "17  14.087084  \n",
      "18  15.916101  \n",
      "19  18.251946  \n",
      "\n",
      "[20 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "#Get counts of male students by region, collape on gender.\n",
    "GenCounts=GenEth.drop(GenEth.columns[[3,6,8]], axis=1) #axis=0 for rows, axis=1 for columns\n",
    "Allmalestemp=GenCounts.loc[GenCounts['Gender']=='Male'].copy() #copy to avoid chained indexing\n",
    "Allmales=Allmalestemp.groupby([\"TEAReg\", \"RegName\"], as_index=False).sum().copy()\n",
    "Allmales['AllmpEnr']=100*Allmales['nEnr']/Allmales['CohoN']\n",
    "Allmales['AllmpComp']=100*Allmales['nComp']/Allmales['CohoN']\n",
    "Allmales.columns=['TEAReg', 'RegName','TotmCoho', 'TotmnEnr','TotmnComp','TotmpEnr','TotmpComp']\n",
    "\n",
    "\n",
    "print(Allmales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data on economically disadvantaged students by TEA region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    TEAReg         RegName  EcoCoho  EconEnr  EcopEnr  EconComp  EcopComp\n",
      "1        1        Edinburg  22598.0  11792.0    52.18    4348.0     19.24\n",
      "3        2  Corpus Christi   4284.0   1769.0    41.29     472.0     11.02\n",
      "5        3        Victoria   1954.0    739.0    37.82     205.0     10.49\n",
      "7        4         Houston  37004.0  16213.0    43.81    4972.0     13.44\n",
      "9        5        Beaumont   2952.0   1213.0    41.09     341.0     11.55\n",
      "..     ...             ...      ...      ...      ...       ...       ...\n",
      "31      16        Amarillo   2928.0   1264.0    43.17     389.0     13.29\n",
      "33      17         Lubbock   2987.0   1163.0    38.94     322.0     10.78\n",
      "35      18         Midland   2481.0    918.0    37.00     266.0     10.72\n",
      "37      19         El Paso   9495.0   5299.0    55.81    1583.0     16.67\n",
      "39      20     San Antonio  15791.0   6759.0    42.80    2224.0     14.08\n",
      "\n",
      "[20 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "xlEcon = pd.read_excel('Data\\8th Grade FY2008 Cohort Workbook.xlsx', sheet_name='TEA Region by Eco', header=None, index_col=None, skiprows=6)\n",
    "\n",
    "#Keep just the columns you need\n",
    "xlEcon2=xlEcon[[0,1,2,3,16,17,20,21]]\n",
    "EconTemp=xlEcon2.loc[xlEcon2[2]=='Economically Disadvantaged'].copy()\n",
    "\n",
    "EconTemp2=EconTemp.drop([2], axis=1).copy()\n",
    "\n",
    "#Get Region Totals and drop the rows you don't need\n",
    "Econ=EconTemp2[:20].copy()\n",
    "Econ.columns=['TEAReg','RegName','EcoCoho', 'EconEnr', 'EcopEnr', 'EconComp', 'EcopComp']\n",
    "\n",
    "Econ['EcopEnr']=100*Econ['EcopEnr']\n",
    "Econ['EcopComp']=100*Econ['EcopComp']\n",
    "Econ['TEAReg']=Econ['TEAReg'].astype(int) #Make sure region in an integer for merging later\n",
    "\n",
    "print(Econ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Get overall totals by region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    TEAReg         RegName  TotCoho  TotnEnr    TotpEnr  TotnComp   TotpComp\n",
      "0        1        Edinburg  26668.0  14822.0  55.579721    5926.0  22.221389\n",
      "1        2  Corpus Christi   7574.0   3919.0  51.742804    1484.0  19.593346\n",
      "2        3        Victoria   3850.0   2047.0  53.168831     910.0  23.636364\n",
      "3        4         Houston  73414.0  40109.0  54.633994   17037.0  23.206745\n",
      "4        5        Beaumont   5979.0   3117.0  52.132464    1277.0  21.358087\n",
      "..     ...             ...      ...      ...        ...       ...        ...\n",
      "15      16        Amarillo   5719.0   3112.0  54.415108    1324.0  23.150901\n",
      "16      17         Lubbock   5373.0   2773.0  51.609901    1199.0  22.315280\n",
      "17      18         Midland   5361.0   2618.0  48.834173    1040.0  19.399366\n",
      "18      19         El Paso  12771.0   7522.0  58.899068    2518.0  19.716545\n",
      "19      20     San Antonio  27342.0  14330.0  52.410211    6217.0  22.737912\n",
      "\n",
      "[20 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "xl = pd.read_excel('Data\\8th Grade FY2008 Cohort Workbook.xlsx', sheet_name='Summary', header=None, index_col=None, skiprows=16)\n",
    "\n",
    "#Keep the columns you need\n",
    "xl2=xl[[0,1,2,15,16,19,20]]\n",
    "\n",
    "#Get Region Totals and drop the rows you don't need\n",
    "RegTotals=xl2[:20].copy()\n",
    "RegTotals.columns=['TEAReg','RegName','TotCoho', 'TotnEnr', 'TotpEnr', 'TotnComp', 'TotpComp']\n",
    "\n",
    "RegTotals['TotpEnr']=100*RegTotals['TotpEnr']\n",
    "RegTotals['TotpComp']=100*RegTotals['TotpComp']\n",
    "RegTotals['TEAReg']=RegTotals['TEAReg'].astype(int) #Make sure region in an integer for merging later\n",
    "\n",
    "print(RegTotals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Merge into one table, create additional variables, and finalize formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    TEAReg         RegName   AACoho  AAnEnr  AAnComp  AApEnr  AApComp  \\\n",
      "0        1        Edinburg     65.0    42.0     20.0    64.6     30.8   \n",
      "1        2  Corpus Christi    291.0   146.0     37.0    50.2     12.7   \n",
      "2        3        Victoria    396.0   210.0     45.0    53.0     11.4   \n",
      "3        4         Houston  16341.0  9148.0   2491.0    56.0     15.2   \n",
      "4        5        Beaumont   1777.0   951.0    250.0    53.5     14.1   \n",
      "..     ...             ...      ...     ...      ...     ...      ...   \n",
      "15      16        Amarillo    323.0   173.0     35.0    53.6     10.8   \n",
      "16      17         Lubbock    433.0   201.0     47.0    46.4     10.9   \n",
      "17      18         Midland    244.0   108.0     35.0    44.3     14.3   \n",
      "18      19         El Paso    384.0   166.0     48.0    43.2     12.5   \n",
      "19      20     San Antonio   2110.0  1089.0    371.0    51.6     17.6   \n",
      "\n",
      "    HisCoho  HisnEnr  HisnComp    ...     HispCoho_  EcopCoho_  AAComppD_  \\\n",
      "0   25765.0  14238.0    5617.0    ...          97.0       85.0        9.0   \n",
      "1    5124.0   2501.0     840.0    ...          68.0       57.0       -7.0   \n",
      "2    1810.0    748.0     240.0    ...          47.0       51.0      -12.0   \n",
      "3   30602.0  13570.0    4935.0    ...          42.0       50.0       -8.0   \n",
      "4     660.0    265.0     136.0    ...          11.0       49.0       -7.0   \n",
      "..      ...      ...       ...    ...           ...        ...        ...   \n",
      "15   2177.0    964.0     334.0    ...          38.0       51.0      -12.0   \n",
      "16   2691.0   1132.0     355.0    ...          50.0       56.0      -11.0   \n",
      "17   3142.0   1389.0     466.0    ...          59.0       46.0       -5.0   \n",
      "18  11246.0   6737.0    2193.0    ...          88.0       74.0       -7.0   \n",
      "19  17903.0   8731.0    3266.0    ...          65.0       58.0       -5.0   \n",
      "\n",
      "    HisComppD_  EcoComppD_  AAEnrpD_  HisEnrpD_  EcoEnrpD_  MaleEnrpD_  \\\n",
      "0         -0.0        -3.0       9.0       -0.0       -3.0        -4.0   \n",
      "1         -3.0        -9.0      -2.0       -3.0      -10.0        -5.0   \n",
      "2        -10.0       -13.0      -0.0      -12.0      -15.0        -6.0   \n",
      "3         -7.0       -10.0       1.0      -10.0      -11.0        -5.0   \n",
      "4         -1.0       -10.0       1.0      -12.0      -11.0        -5.0   \n",
      "..         ...         ...       ...        ...        ...         ...   \n",
      "15        -8.0       -10.0      -1.0      -10.0      -11.0        -6.0   \n",
      "16        -9.0       -12.0      -5.0      -10.0      -13.0        -5.0   \n",
      "17        -5.0        -9.0      -5.0       -5.0      -12.0        -8.0   \n",
      "18        -0.0        -3.0     -16.0        1.0       -3.0        -4.0   \n",
      "19        -4.0        -9.0      -1.0       -4.0      -10.0        -5.0   \n",
      "\n",
      "    MaleCpD_  \n",
      "0       -4.0  \n",
      "1       -3.0  \n",
      "2       -3.0  \n",
      "3       -4.0  \n",
      "4       -3.0  \n",
      "..       ...  \n",
      "15      -4.0  \n",
      "16      -4.0  \n",
      "17      -5.0  \n",
      "18      -4.0  \n",
      "19      -4.0  \n",
      "\n",
      "[20 rows x 55 columns]\n"
     ]
    }
   ],
   "source": [
    "#Combine into one table\n",
    "All=pd.merge(AA, Hisp,on=['TEAReg', 'RegName']).copy()\n",
    "All=pd.merge(All, Allmales,on=['TEAReg', 'RegName']).copy()\n",
    "All=pd.merge(All, RegTotals,on=['TEAReg', 'RegName']).copy()\n",
    "All=pd.merge(All, Econ,on=['TEAReg', 'RegName']).copy()\n",
    "\n",
    "#Calculate % point differences for AA/Hisp/Males/Eco enrollmnet and completion rates from total cohort by region\n",
    "All['AAEnrpDi']=All['AApEnr']-All['TotpEnr']\n",
    "All['HisEnrpDi']=All['HispEnr']-All['TotpEnr']\n",
    "All['MaleEnrpDi']=All['TotmpEnr']-All['TotpEnr'] #all males\n",
    "All['EcoEnrpDi']=All['EcopEnr']-All['TotpEnr']\n",
    "All['AAComppDi']=All['AApComp']-All['TotpComp']\n",
    "All['HisComppDi']=All['HispComp']-All['TotpComp']\n",
    "All['MaleCpDi']=All['TotmpComp']-All['TotpComp'] #all males\n",
    "All['EcoComppDi']=All['EcopComp']-All['TotpComp']\n",
    "\n",
    "Final=All\n",
    "\n",
    "#Make perc of total for AA, Hisp, and Eco\n",
    "Final['AApCoho']=100*All['AACoho']/All['TotCoho']\n",
    "Final['HispCoho']=100*All['HisCoho']/All['TotCoho']\n",
    "Final['EcopCoho']=100*All['EcoCoho']/All['TotCoho']\n",
    "\n",
    "#Make variables with \"_\" suffix. They will have zero decmals and be used as symbol layers\n",
    "Final['TotpEnr_']=Final['TotpEnr']\n",
    "Final['TotpComp_']=Final['TotpComp'] \n",
    "Final['TotmpComp_']=Final['TotmpComp']\n",
    "Final['AApComp_']=Final['AApComp']\n",
    "Final['HispComp_']=Final['HispComp']\n",
    "Final['EcopComp_']=Final['EcopComp']\n",
    "\n",
    "\n",
    "Final['AApCoho_']=Final['AApCoho']\n",
    "Final['HispCoho_']=Final['HispCoho']\n",
    "Final['EcopCoho_']=Final['EcopCoho']\n",
    "Final['AAComppD_']=Final['AAComppDi']\n",
    "Final['HisComppD_']=Final['HisComppDi']\n",
    "Final['EcoComppD_']=Final['EcoComppDi']\n",
    "Final['AAEnrpD_']=Final['AAEnrpDi']\n",
    "Final['HisEnrpD_']=Final['HisEnrpDi']\n",
    "Final['EcoEnrpD_']=Final['EcoEnrpDi']\n",
    "Final['MaleEnrpD_']=Final['MaleEnrpDi']\n",
    "Final['MaleCpD_']=Final['MaleCpDi']\n",
    "\n",
    "\n",
    "#set percentages to have just one decimal place\n",
    "Processed = Final.round({'AApEnr': 1, 'AApComp': 1, \n",
    "             'HispEnr': 1, 'HispComp': 1, \n",
    "             'TotmpEnr': 1, 'TotmpComp': 1, \n",
    "             'TotpEnr': 1, 'TotpComp': 1, \n",
    "            'AAEnrpDi': 1,  'AAComppDi': 1,\n",
    "            'HisEnrpDi': 1, 'HisComppDi': 1, \n",
    "             'AApCoho': 1, 'HispCoho': 1, 'EcopCoho':1,  \n",
    "             'EcopEnr': 1, 'EcopComp': 1, \n",
    "            'EcoEnrpDi': 1, 'EcoComppDi': 1, \n",
    "            'MaleEnrpDi':1, 'MaleCpDi':1,\n",
    "            'TotpEnr_':0, 'TotpComp_':0, 'TotmpComp_': 0,\n",
    "            'AApComp_': 0, 'HispComp_': 0, 'EcopComp_': 0, \n",
    "            'AApCoho_':0, 'HispCoho_':0, 'EcopCoho_':0, \n",
    "            'AAComppD_':0, 'HisComppD_':0, 'EcoComppD_':0, 'MaleCpD_':0,\n",
    "            'AAEnrpD_':0, 'HisEnrpD_':0, 'EcoEnrpD_':0, 'MaleEnrpD_':0}).copy()\n",
    "\n",
    "Processed.to_csv('Data/ProcessedData.csv', index=False)\n",
    "print(Processed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now split our prepared data into two datasets. One for points and one for polygons\n",
    "The Polygon data will have all the variables except for the percentages rounded to zero decimals. The Point data will just have the rounded off percentages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Polygon data\n",
    "ProcessedPolys=Processed.iloc[:,0:38].copy() \n",
    "ProcessedPolys.to_csv('Data/ProcessedPolys.csv', index=False)\n",
    "\n",
    "#Point Data\n",
    "ProcessedPoints=Processed.iloc[:,numpy.r_[0:1,38:55]].copy()\n",
    "ProcessedPoints.to_csv('Data/ProcessedPoints.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# The rest of the code prepares the shapefiles for mapping.\n",
    "\n",
    "### But first, download and save the Education Service Center region (TEA region) shapefiles:\n",
    "    \n",
    "* Polygons for TEA Regions [available from TEA](http://schoolsdata2-tea-texas.opendata.arcgis.com). Download the [Education Service Center Regions](http://opendata.arcgis.com/datasets/12142ff8beec4a1797334c9c41ba7b18_0.zip). Unzip the file and store the contents in a new folder: Data/rawESC_Regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBJECTID_1 is a type of OID with a length of 4\n",
      "Shape is a type of Geometry with a length of 0\n",
      "FID_1 is a type of Integer with a length of 4\n",
      "OBJECTID is a type of Integer with a length of 4\n",
      "CITY is a type of String with a length of 80\n",
      "REGION is a type of String with a length of 80\n",
      "ORG_E_ID is a type of Integer with a length of 4\n",
      "WEBSITE is a type of String with a length of 80\n",
      "SHAPE_Leng is a type of Double with a length of 8\n",
      "Shape_Length is a type of Double with a length of 8\n",
      "Shape_Area is a type of Double with a length of 8\n"
     ]
    }
   ],
   "source": [
    "#copy shapefiles to geodatabase\n",
    "arcpy.FeatureClassToGeodatabase_conversion('Data/rawESC_Regions/ESC_Regions.shp', 'Data/Cohort.gdb')\n",
    "\n",
    "#List fields in dataset\n",
    "fields = arcpy.ListFields('Data/Cohort.gdb/ESC_Regions')\n",
    "\n",
    "for field in fields:\n",
    "    print(\"{0} is a type of {1} with a length of {2}\"\n",
    "          .format(field.name, field.type, field.length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Result 'Data/Cohort.gdb/ESC_Regions'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Delete unnecessary fields\n",
    "arcpy.DeleteField_management(\"Data/Cohort.gdb/ESC_Regions\", [\"FID_1\", \"OBJECTID\", \"CITY\", 'REGION', 'ORG_E_ID', 'WEBSITE', 'SHAPE_Leng'])                            \n",
    "\n",
    "#Create Texas Outline by dissolving the TEA region polygons\n",
    "arcpy.Dissolve_management(\"Data/Cohort.gdb/ESC_Regions\",\"Data/Cohort.gdb/TexasOutline\")\n",
    "\n",
    "#Add datasets to GeoDataBase\n",
    "arcpy.TableToTable_conversion('Data/ProcessedPolys.csv', 'Data/Cohort.gdb', 'PolygonData')\n",
    "arcpy.TableToTable_conversion('Data/ProcessedPoints.csv', 'Data/Cohort.gdb', 'PointData')\n",
    "\n",
    "#Merge Cohort Data to TEA Region Polygons\n",
    "arcpy.JoinField_management('Data/Cohort.gdb/ESC_Regions', 'OBJECTID_1','Data/Cohort.gdb/PolygonData', 'TEAReg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Result 'Data\\\\FinalShapefiles'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make folder if it doesn't exist\n",
    "if not os.path.exists('Data/FinalShapefiles'):\n",
    "    os.makedirs('Data/FinalShapefiles')\n",
    "    \n",
    "#Export merged TEARegions with Cohort data to shapefile\n",
    "arcpy.FeatureClassToShapefile_conversion ('Data/Cohort.gdb/ESC_Regions', 'Data/FinalShapefiles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now make the centrids for the TEA Regions\n",
    "\n",
    "(Requires the advanced license)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Result 'Data/Cohort.gdb/ESC_Points'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Set local variables\n",
    "inFeatures = 'Data/rawESC_Regions/ESC_Regions.shp'\n",
    "outFeatureClass = \"Data/Cohort.gdb/ESC_Points\"\n",
    "\n",
    "# Use FeatureToPoint function to find a point inside each park\n",
    "arcpy.FeatureToPoint_management(inFeatures, outFeatureClass)\n",
    "\n",
    "#Merge Cohort Data to TEA Region Polygons\n",
    "arcpy.JoinField_management('Data/Cohort.gdb/ESC_Points', 'OBJECTID_1','Data/Cohort.gdb/PointData', 'TEAReg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Result 'Data\\\\FinalShapefiles'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Export merged TEARegion Points to shapefile\n",
    "arcpy.FeatureClassToShapefile_conversion ('Data/Cohort.gdb/ESC_Points', 'Data/FinalShapefiles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a mask around the state of Texas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Result 'Data\\\\Cohort.gdb\\\\TempMask'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A list coordinate pairs\n",
    "feature_info = [[[-140, 15], [-60, 15], [-60, 45], [-140, 45], [-140, 15]]]\n",
    "\n",
    "# A list that will hold each of the Polygon objects\n",
    "features = []\n",
    "\n",
    "for feature in feature_info:\n",
    "    # Create a Polygon object based on the array of points\n",
    "    features.append(\n",
    "        arcpy.Polygon(\n",
    "            arcpy.Array([arcpy.Point(*coords) for coords in feature])))\n",
    "\n",
    "# Persist a copy of the Polyline objects using CopyFeatures\n",
    "arcpy.CopyFeatures_management(features, \"Data/Cohort.gdb/TempMask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Result 'Data\\\\FinalShapefiles\\\\TexasMask.shp'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carve out the shape of Texas for the mask\n",
    "arcpy.Erase_analysis(\"Data/Cohort.gdb/TempMask\", \"Data/Cohort.gdb/TexasOutline\", \"Data/FinalShapefiles/TexasMask.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, go to linux and use GDAL to convert shapefiles to geojson. Then use the Tippecanoe tool to make .MBtiles\n",
    "\n",
    "I used the following commands:\n",
    "\n",
    "`ogr2ogr -f GeoJSON Data/CohortTEARegionPolys.json Data/FinalShapefiles/ESC_Regions.shp -progress`\n",
    "\n",
    "`ogr2ogr -f GeoJSON Data/TexasOutline.json Data/FinalShapefiles/TexasOutline.shp -progress`\n",
    "\n",
    "`ogr2ogr -f GeoJSON Data/CohortTEARegionPoints.json Data/FinalShapefiles/ESC_Points.shp -progress`\n",
    "\n",
    "`ogr2ogr -f GeoJSON Data/TexasMask.json Data/FinalShapefiles/TexasMask.shp -progress`\n",
    "\n",
    "`tippecanoe --output=8thGradeCohort2008TEARegionData.mbtiles Data/CohortTEARegionPoints.json Data/CohortTEARegionPolys.json Data/TexasMask.json -r1 --drop-fraction-as-needed  --simplification=9 --maximum-zoom=8 --minimum-zoom=3 --exclude=OBJECTID_1 --detect-shared-borders`\n",
    "\n",
    "Finally, we uploaded the custom .MBtiles to mapbox studio and served them from there. You could also set up your own vector tile server using TileServer-GL."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
